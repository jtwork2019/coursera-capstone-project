{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Peer-graded Assignment: Segmenting and Clustering Neighborhoods in Toronto", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Firstly, import the libraries", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n#!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n#!conda install -c conda-forge folium=0.5.0 --yes\nimport folium # map rendering library\n\nprint('Libraries imported.')"
        }, 
        {
            "source": "### scrape the following Wikipedia page, https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from bs4 import BeautifulSoup\nimport urllib.request\n\nurl = 'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'\nreq = urllib.request.urlopen(url)\narticle = req.read().decode()\n\nwith open('ISO_3166-1_alpha-2.html', 'w') as fo:\n    fo.write(article)\n    \nsoup = BeautifulSoup(article, 'html.parser')"
        }, 
        {
            "source": "### obtain the data that is in the table of postal codes and to transform the data into a pandas dataframe df", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "tables = soup.find_all('table', class_='sortable')\nfor table in tables:\n    ths = table.find_all('th')\n    headings = [th.text.strip() for th in ths]\n    if headings[:3] == ['Postcode', 'Borough', 'Neighbourhood']:\n        break"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df = pd.DataFrame(columns=headings)\ni=0\n\nfor tr in table.find_all('tr'):\n        tds = tr.find_all('td')\n        if not tds:\n            continue\n        postcode, borough, neighbourhood = [td.text.strip() for td in tds[:3]]\n        \n        # Ignore cells with a borough that is Not assigned.\n        if 'Not assigned' in borough:\n            continue\n        # If a cell has a borough but a Not assigned neighborhood, \n        # then the neighborhood will be the same as the borough. \n        if 'Not assigned' in neighbourhood:\n            neighbourhood = borough\n        df.loc[i] = [postcode, borough, neighbourhood]\n        i=i+1"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from functools import reduce\n\ndef to_set(x):\n    setx = set(x)\n    strs = ', '.join(setx)   \n    return strs\n\n#grouped = df.groupby(\"Postcode\").agg({'Neighbourhood': to_set})\n\ngrouped = df.groupby(\"Postcode\").agg({'Borough':'first', 'Neighbourhood': to_set})\n\ndf2 = df.drop(columns='Neighbourhood')\ngrouped = grouped.reset_index()\n\n#grouped = pd.merge(df2, grouped, how='inner', on='Postcode')\n\n    \n#grouped = pd.DataFrame({'Qty_cnt' : df['Borough'], grouped]\n\ngrouped[['Postcode','Borough','Neighbourhood']]"
        }, 
        {
            "source": "### In the last cell of your notebook, use the .shape method to print the number of rows of your dataframe.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "grouped.shape"
        }, 
        {
            "source": "### Part 2:  get the latitude and the longitude coordinates of each neighborhood.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#!conda install -c conda-forge geocoder  #install geocoder for the 1st run\nimport geocoder # import geocoder"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Comment:\n# I tried to use geocoder, but the API seems not working, \n# so I choose to use the csv file instead\n#\n#nbh = 'Malvern, Rouge'\n#postal_code = 'M1B'\n#g = geocoder.google(nbh)\n#lat_lng_coords = g.latlng"
        }, 
        {
            "source": "### Import lat_lng_coords CSV, and show the complete dataframe", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df_ll = pd.read_csv(\"https://cocl.us/Geospatial_data\")\n\n#latitude = lat_lng_coords[0]\n#longitude = lat_lng_coords[1]\ng2 = grouped[['Postcode','Borough','Neighbourhood']]\nd2 = df_ll.rename(index=str, columns={\"Postal Code\": \"Postcode\"})\ng2 = pd.merge(d2, g2, how='inner', on='Postcode')\n\ng2 = g2[['Postcode','Borough','Neighbourhood', 'Latitude', 'Longitude']]\ng2\n"
        }, 
        {
            "source": "### Part 3: Cluster Neighborhoods", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Define Foursquare Credentials and Version", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "source": "#### Locate the latitude and longitude of Toronto City", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "address = 'Toronto'\n\ngeolocator = Nominatim(user_agent=\"tt_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of Toronto are {}, {}.'.format(latitude, longitude))"
        }, 
        {
            "source": "#### Create a map of Toronto with neighborhoods superimposed on top", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# create map of New York using latitude and longitude values\nmap_toronto = folium.Map(location=[latitude, longitude], zoom_start=10)\n\nneighborhoods = g2\n\n# add markers to map\nfor lat, lng, borough, neighborhood in zip(neighborhoods['Latitude'], neighborhoods['Longitude'], neighborhoods['Borough'], neighborhoods['Neighbourhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_toronto)  \n    \nmap_toronto"
        }, 
        {
            "source": "#### Explore and cluster the neighborhoods in Toronto. \n#### (We work with only boroughs that contain the word Toronto)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "myList = []\nfor b in neighborhoods['Borough']:\n    myList.append('Toronto' in b)\n    #print('Toronto' in b)\n    \ntoronto_data = neighborhoods[myList].reset_index(drop=True)\ntoronto_data.head()"
        }, 
        {
            "source": "#### Test with the first Neighbourhood in Toronto Data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "toronto_data.loc[0, 'Neighbourhood']"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "neighborhood_latitude = toronto_data.loc[0, 'Latitude'] # neighborhood latitude value\nneighborhood_longitude = toronto_data.loc[0, 'Longitude'] # neighborhood longitude value\n\nneighborhood_name = toronto_data.loc[0, 'Neighbourhood'] # neighborhood name\n\nprint('Latitude and longitude values of {} are {}, {}.'.format(neighborhood_name, \n                                                               neighborhood_latitude, \n                                                               neighborhood_longitude))"
        }, 
        {
            "source": "#### Next, get the top 100 venues that are in The Beaches within a radius of 500 meters.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# type your answer here\nLIMIT = 100 # limit of number of venues returned by Foursquare API\nradius = 500 # define radius\nurl = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n    CLIENT_ID, \n    CLIENT_SECRET, \n    VERSION, \n    neighborhood_latitude, \n    neighborhood_longitude, \n    radius, \n    LIMIT)\n#url # display URL\n\nresults = requests.get(url).json()\nresults"
        }, 
        {
            "source": "#### We read all the information is in the items key of Foursquare API:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# function that extracts the category of the venue\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']"
        }, 
        {
            "source": "#### and we restructure the data into dataframe:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "venues = results['response']['groups'][0]['items']\n    \nnearby_venues = json_normalize(venues) # flatten JSON\n\n# filter columns\nfiltered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\nnearby_venues =nearby_venues.loc[:, filtered_columns]\n\n# filter the category for each row\nnearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n\n# clean columns\nnearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n\nnearby_venues.head()"
        }, 
        {
            "source": "#### Hence, we know the number of venues obtained from Foursquare:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "print('{} venues were returned by Foursquare.'.format(nearby_venues.shape[0]))"
        }, 
        {
            "source": "#### In further analysis, we create a function to repeat the same process to all the neighborhoods in Toronto", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighbourhood', \n                  'Neighbourhood Latitude', \n                  'Neighbourhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        }, 
        {
            "source": "#### Then, we run the above function on each neighborhood and create a new dataframe called toronto_venues", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "toronto_venues = getNearbyVenues(names=toronto_data['Neighbourhood'],\n                                   latitudes=toronto_data['Latitude'],\n                                   longitudes=toronto_data['Longitude']\n                                  )"
        }, 
        {
            "source": "#### The sizes of the toronto_venue data is:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "print(toronto_venues.shape)\ntoronto_venues.head()"
        }, 
        {
            "source": "#### The number of venues were returned for each neighborhood as below:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "toronto_venues.groupby('Neighbourhood').count()"
        }, 
        {
            "source": "#### The number of unique categories is shown below:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "print('There are {} uniques categories.'.format(len(toronto_venues['Venue Category'].unique())))"
        }, 
        {
            "source": "#### Next, we further analysis the neighbourhood:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# one hot encoding\ntoronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\ntoronto_onehot['Neighbourhood'] = toronto_venues['Neighbourhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [toronto_onehot.columns[-1]] + list(toronto_onehot.columns[:-1])\ntoronto_onehot = toronto_onehot[fixed_columns]\n\ntoronto_onehot.head()\n\n"
        }, 
        {
            "source": "#### The new dataframe size is:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "toronto_onehot.shape"
        }, 
        {
            "source": "#### And then, we group rows by neighbourhood and by taking the mean of the frequency of occurrence of each category", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "toronto_grouped = toronto_onehot.groupby('Neighbourhood').mean().reset_index()\ntoronto_grouped"
        }, 
        {
            "source": "#### The new dataframe size is confirmed as:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "toronto_grouped.shape"
        }, 
        {
            "source": "#### We then print each neighborhood along with the top 5 most common venues", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "num_top_venues = 5\n\nfor hood in toronto_grouped['Neighbourhood']:\n    print(\"----\"+hood+\"----\")\n    temp = toronto_grouped[toronto_grouped['Neighbourhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')"
        }, 
        {
            "source": "#### We then sort the venues in descending order, and put into a pandas dataframe", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighbourhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighbourhood'] = toronto_grouped['Neighbourhood']\n\nfor ind in np.arange(toronto_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(toronto_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()"
        }, 
        {
            "source": "#### Finally, we run k-means to cluster the neighborhood into 5 clusters.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# set number of clusters\nkclusters = 5\n\ntoronto_grouped_clustering = toronto_grouped.drop('Neighbourhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(toronto_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10] \n\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n\ntoronto_merged = toronto_data\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\ntoronto_merged = toronto_merged.join(neighborhoods_venues_sorted.set_index('Neighbourhood'), on='Neighbourhood')\n\ntoronto_merged.head() # check the last columns!"
        }, 
        {
            "source": "#### Finally, we visualize the resulting clusters", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(toronto_merged['Latitude'], toronto_merged['Longitude'], toronto_merged['Neighbourhood'], toronto_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters"
        }, 
        {
            "source": "#### Follow up: Cluster examination", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 0, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 1, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 2, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 3, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 4, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}